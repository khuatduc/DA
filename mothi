#!pip install git+https://github.com/Optical-Networks-Group/rsa-rl.git
import numpy as np
from rsarl.envs import DeepRMSAEnv
from rsarl.requester import UniformRequester
from rsarl.networks import SingleFiberNetwork
from rsarl.agents.ksp_agents import KSP_FF_Agent
_file = open('result1.csv', 'w')
avg_request_arrival_rate=0.6
while(avg_request_arrival_rate<=1.5):
    # build network: topology-name, the number of slots, whether to consider weighted edges or not
    net = SingleFiberNetwork("nsf", n_slot=80, is_weight=True)
    # build requester
    requester = UniformRequester(
        net.n_nodes,  
        avg_service_time=100,
        avg_request_arrival_rate=avg_request_arrival_rate)
# Reward is +1 if assignment succeeds; otherwise -1. 
    env = DeepRMSAEnv(net, requester)
# setting seed for reproductivity
    env.seed(0)
# build agent
    agent = KSP_FF_Agent(k=5)
# pre-calculate all path related to all combination of a pair of nodes
    agent.prepare_ksp_table(net)
# exp settings
    n_requests = 10000

# metrics
    n_blocking = 0
    total_reward = 0

    obs = env.reset()
    for _ in range(n_requests):
    # Get action from observation
        act = agent.act(obs)
    # Do action and get next state
        obs, reward, done, info = env.step(act)
    # Store next state
        if done:
            obs = env.reset()
        
    # calc performance
        n_blocking += 0 if info["is_success"] else 1
        total_reward += reward

    
    print(f'Blocking Probability: {n_blocking / n_requests }')
    print(f'Total Rewards: {total_reward}')
    from rsarl.evaluator import evaluation
    env.reset()
    experiences = evaluation(env, agent, n_requests)
# calc performance
    n_blocking = sum([0 if x.is_success else 1 for x in experiences])
    total_reward = sum([x.reward for x in experiences])

    print(f'Blocking Probability: {n_blocking / n_requests }')
    print(f'Total Rewards: {total_reward}')
    from rsarl.evaluator import summary
# calc performance
    blocking_prob, avg_util, total_reward = summary(experiences)

    print(f'Blocking Probability: {blocking_prob}')
    print(f'Avg. Slot-utilization: {avg_util}')
    print(f'Total Rewards: {total_reward}')
    from rsarl.envs import make_multiprocess_vector_env, make_serial_vector_env
    from rsarl.evaluator import batch_warming_up, batch_evaluation
    seed = 0
    n_envs = 30
# build batch-env
    envs = make_serial_vector_env(env, n_envs, seed, test=True)
    envs.reset()
# If you want to process some number of requests before evaluation, 
# warming_up function runs. 
    batch_warming_up(envs, agent, n_requests=3000)
# evaluation
    experiences = batch_evaluation(envs, agent, n_requests=n_requests)
    # calc performance
    from rsarl.evaluator import batch_summary
    blocking_probs, avg_utils, total_rewards = batch_summary(experiences)

    for env_id, (blocking_prob, avg_util, total_reward) in enumerate(zip(blocking_probs, avg_utils, total_rewards)):
        print(f'[{env_id}-th ENV]Blocking Probability: {blocking_prob}')
        print(f'[{env_id}-th ENV]Avg. Slot-utilization: {avg_util}')
        print(f'[{env_id}-th ENV]Total Rewards: {total_reward}')
# envs = make_multiprocess_vector_env(env, n_envs, seed, test=True)
        _file.write(str(n_envs)+","+str(avg_request_arrival_rate)+","+str(env_id)+","+str(blocking_prob)+","+str(avg_util)+","+str(total_reward)+"\n");
    avg_request_arrival_rate=avg_request_arrival_rate+0.1;


