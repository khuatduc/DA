{"cells":[{"cell_type":"markdown","metadata":{"id":"zewQ8m6diTS8"},"source":["## Tutorial 3: Demonstration of developing original *Agent* with DRL\n","This tutorial demonstrate how to develop *Agent* with DRL algorithm by using ***KSPDRLAgent*** . \n","\n","*Agent* base classes are as follows: \n","\n","- `Agent`(used in **Tutorial 2**)\n","- `KSPAgent`(used in **Tutorial 2**)\n","- `PrioritizedKSPAgent`(used in **Tutorial 2**)\n","- `KSPDRLAgent`"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":48939,"status":"ok","timestamp":1606444394375,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"P8UGHoZ6iVV2","outputId":"960c37fe-e824-4574-a452-225aa73713be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/Optical-Networks-Group/rsa-rl.git\n","  Cloning https://github.com/Optical-Networks-Group/rsa-rl.git to c:\\users\\khuatduc\\appdata\\local\\temp\\pip-req-build-09phlp88\n","  Resolved https://github.com/Optical-Networks-Group/rsa-rl.git to commit 4b82c519742fa47b1537204780174cdb0c2f4ae0\n","Requirement already satisfied: bitarray>=1.2.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (2.3.0)\n","Requirement already satisfied: networkx>=2.5 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (2.5)\n","Requirement already satisfied: tensorboard>=2.2.2 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (2.4.0)\n","Requirement already satisfied: tensorboardX>=2.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (2.5)\n","Requirement already satisfied: torch>=1.5.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (1.10.2)\n","Requirement already satisfied: plotly>=4.9.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (5.6.0)\n","Requirement already satisfied: dash>=1.14.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (2.2.0)\n","Requirement already satisfied: dash-bootstrap-components>=0.10.7 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (1.0.3)\n","Requirement already satisfied: pfrl>=0.1.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from rsarl==1.0.0) (0.3.0)\n","Requirement already satisfied: Flask>=1.0.4 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from dash>=1.14.0->rsarl==1.0.0) (1.1.2)\n","Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from dash>=1.14.0->rsarl==1.0.0) (2.0.0)\n","Requirement already satisfied: dash-table==5.0.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from dash>=1.14.0->rsarl==1.0.0) (5.0.0)\n","Requirement already satisfied: flask-compress in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from dash>=1.14.0->rsarl==1.0.0) (1.11)\n","Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from dash>=1.14.0->rsarl==1.0.0) (2.0.0)\n","Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.14.0->rsarl==1.0.0) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.14.0->rsarl==1.0.0) (2.11.3)\n","Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.14.0->rsarl==1.0.0) (1.0.1)\n","Requirement already satisfied: click>=5.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.14.0->rsarl==1.0.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=1.14.0->rsarl==1.0.0) (2.0.1)\n","Requirement already satisfied: decorator>=4.3.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from networkx>=2.5->rsarl==1.0.0) (5.0.6)\n","Requirement already satisfied: numpy>=1.10.4 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from pfrl>=0.1.0->rsarl==1.0.0) (1.20.2)\n","Requirement already satisfied: pillow in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from pfrl>=0.1.0->rsarl==1.0.0) (8.4.0)\n","Requirement already satisfied: gym>=0.9.7 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from pfrl>=0.1.0->rsarl==1.0.0) (0.21.0)\n","Requirement already satisfied: filelock in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from pfrl>=0.1.0->rsarl==1.0.0) (3.4.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from gym>=0.9.7->pfrl>=0.1.0->rsarl==1.0.0) (1.6.0)\n","Requirement already satisfied: importlib-metadata>=4.8.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from gym>=0.9.7->pfrl>=0.1.0->rsarl==1.0.0) (4.11.1)\n","Requirement already satisfied: zipp>=0.5 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.1->gym>=0.9.7->pfrl>=0.1.0->rsarl==1.0.0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.1->gym>=0.9.7->pfrl>=0.1.0->rsarl==1.0.0) (3.7.4.3)\n","Requirement already satisfied: six in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from plotly>=4.9.0->rsarl==1.0.0) (1.16.0)\n","Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from plotly>=4.9.0->rsarl==1.0.0) (8.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (3.17.2)\n","Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (1.35.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (1.21.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (0.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (2.25.1)\n","Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (58.0.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (1.6.0)\n","Requirement already satisfied: wheel>=0.26 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (0.36.2)\n","Requirement already satisfied: absl-py>=0.4 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.2->rsarl==1.0.0) (0.13.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.2->rsarl==1.0.0) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.2->rsarl==1.0.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.2->rsarl==1.0.0) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.2->rsarl==1.0.0) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.2->rsarl==1.0.0) (0.4.8)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.2->rsarl==1.0.0) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.2->rsarl==1.0.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.2->rsarl==1.0.0) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.2->rsarl==1.0.0) (1.26.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.2->rsarl==1.0.0) (3.1.1)\n","Requirement already satisfied: brotli in c:\\users\\khuatduc\\anaconda3\\lib\\site-packages (from flask-compress->dash>=1.14.0->rsarl==1.0.0) (1.0.9)\n"]},{"name":"stderr","output_type":"stream","text":["  Running command git clone -q https://github.com/Optical-Networks-Group/rsa-rl.git 'C:\\Users\\khuatduc\\AppData\\Local\\Temp\\pip-req-build-09phlp88'\n"]}],"source":["!pip install git+https://github.com/Optical-Networks-Group/rsa-rl.git"]},{"cell_type":"markdown","metadata":{"id":"X__XTKCciTS8"},"source":["## Evaluation Settings\n","For evaluation, prepare *Environment* and evaluation function. \n","Please see **Tutorial 1** if you have not seen it. "]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":54422,"status":"ok","timestamp":1606444399868,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"89r63g3KiTS9"},"outputs":[],"source":["import functools\n","import numpy as np\n","\n","from rsarl.envs import DeepRMSAEnv, make_multiprocess_vector_env\n","from rsarl.requester import UniformRequester\n","from rsarl.networks import SingleFiberNetwork\n","from rsarl.evaluator import batch_warming_up, batch_evaluation, batch_summary"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":54421,"status":"ok","timestamp":1606444399873,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"l1v4_3VuiTS9"},"outputs":[],"source":["# Set the device id to use GPU. To use CPU only, set it to -1.\n","gpu = -1"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":828,"status":"ok","timestamp":1606444612598,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"YPCJzzqPiTS9"},"outputs":[],"source":["# exp settings\n","n_requests = 100\n","n_envs, seed = 2, 0\n","\n","# build network\n","net = SingleFiberNetwork(\"nsf\", n_slot=60, is_weight=True)\n","# build requester\n","requester = UniformRequester(\n","    net.n_nodes,\n","    avg_service_time=10,\n","    avg_request_arrival_rate=12)\n","# build env\n","env = DeepRMSAEnv(net, requester)\n","# envs for training and evaluation\n","envs = make_multiprocess_vector_env(env, n_envs, seed, test=False)\n","test_envs = make_multiprocess_vector_env(env, n_envs, seed, test=True)"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":669,"status":"ok","timestamp":1606444613797,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"ixJW1uumiTS9"},"outputs":[],"source":["def _evaluation(envs, agent, n_requests): \n","    # start simulation\n","    envs.reset()\n","    # \n","    batch_warming_up(envs, agent, n_requests=3000)\n","    # evaluation\n","    experiences = batch_evaluation(envs, agent, n_requests=n_requests)\n","    # calc performance\n","    blocking_probs, avg_utils, total_rewards = batch_summary(experiences)\n","\n","    for env_id, (blocking_prob, avg_util, total_reward) in enumerate(zip(blocking_probs, avg_utils, total_rewards)):\n","        print(f'[{env_id}-th ENV]Blocking Probability: {blocking_prob}')\n","        print(f'[{env_id}-th ENV]Avg. Slot-utilization: {avg_util}')\n","        print(f'[{env_id}-th ENV]Total Rewards: {total_reward}')\n","\n","# evaluation with test environments\n","evaluation = functools.partial(_evaluation, envs=test_envs, n_requests=n_requests)"]},{"cell_type":"markdown","metadata":{"id":"MQd2PXftiTS9"},"source":["## Step1: Select DRL algorithm from PFRL\n","*RSA-RL* assumes that DRL algorithm provided by [PFRL](https://github.com/pfnet/pfrl) library is used. \n","***PFRL*** is a DRL library that implements various state-of-the-art deep reinforcement algorithms in Python using[PyTorch](https://github.com/pytorch/pytorch).  \n","Discrete action algorithms are as follows: \n","\n","- ***DQN(Double DQN)***\n","- ***Rainbow***\n","- ***IQN***\n","- ***A3C***, ***A2C***\n","- ***ACER***\n","- ***PPO***\n","- ***TRPO***\n","\n","In this tutorial, we try to reproduct the prior [DeepRMSA](https://ieeexplore.ieee.org/document/8386173) that applies DRL to ***routing algorithm*** that selects one from the *k* shortest paths. \n","This tutorial call it ***DeepRMSAv1***, and implement it by using ***Double DQN (DDQN)***. \n","In the case of using DDQN, there are three steps:\n","\n","1. Build  deep neural network (DNN) model\n","2. Specify ***Explore*** and ***Replay Buffer***, e.g., epsilon greedy and prioritized replay buffer, respectively\n","3. Build DDQN\n","\n","First, you develop a DNN that the number of outputs is *k*. "]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":54408,"status":"ok","timestamp":1606444399876,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"P7ExKbXSiTS9"},"outputs":[],"source":["import pfrl\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":54404,"status":"ok","timestamp":1606444399877,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"fiBR68HUiTS9"},"outputs":[],"source":["class DeepRMSAv1_DNN(torch.nn.Module):\n","\n","    def __init__(self, SLOT: int, ICH: int, K: int, n_edges: int):\n","        super().__init__()\n","        self.SLOT = SLOT\n","        # CNN\n","        self.conv = nn.Sequential(*[\n","            nn.Conv2d(ICH, 1, kernel_size=(1,1), stride=(1, 1)),\n","            nn.ReLU(),\n","            # 2 conv layers with16 filters\n","            nn.Conv2d(1, 16, kernel_size=(n_edges,1), stride=(1, 1)),\n","            nn.ReLU(),\n","            nn.Conv2d(16, 16, kernel_size=(1,1), stride=(1, 1)),\n","            nn.ReLU(),\n","            # 2 depthwise conv layers with 1 filter\n","            nn.ZeroPad2d((1, 0, 0, 0)), # left, right, top, bottom\n","            nn.Conv2d(16, 16, kernel_size=(1,2), stride=(1, 1), groups=16),\n","            nn.ReLU(),\n","            nn.ZeroPad2d((1, 0, 0, 0)),\n","            nn.Conv2d(16, 16, kernel_size=(1,2), stride=(1, 1), groups=16),\n","            nn.ReLU(),\n","        ])\n","        # fc\n","        self.fc = nn.Sequential(*[\n","            nn.Linear(SLOT*16, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 50),\n","            nn.ReLU(),\n","            nn.Linear(50, K),\n","        ])      \n","\n","    def forward(self, x):\n","        h = x\n","        h = self.conv(h)\n","        h = h.view(-1, self.SLOT*16)\n","        h = self.fc(h)\n","        return pfrl.action_value.DiscreteActionValue(h)"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":54401,"status":"ok","timestamp":1606444399877,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"RJICX7dIiTS9"},"outputs":[],"source":["# Experimental Settings\n","K = 5\n","# slot-table(1) + one-hot-node * 2 + bandwidth(1)\n","ICH = 1 + 2 * net.n_nodes + 1\n","# build DNN for Q-function\n","q_func = DeepRMSAv1_DNN( net.n_slot, ICH, K, net.n_edges)\n","# Specify optimizer \n","optimizer = torch.optim.Adam(q_func.parameters(), eps=1e-2)"]},{"cell_type":"markdown","metadata":{"id":"LeNbJNARiTS9"},"source":["### Specify *Explore* and *Replay Buffer*\n","This tutorial selects ConstantEpsilonGreedy. \n","If you want to use others, please refere *PFRL*'s documentation:\n","- [explore](https://pfrl.readthedocs.io/en/latest/explorers.html)\n","- [replay buffer](https://pfrl.readthedocs.io/en/latest/replay_buffers.html)"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":54398,"status":"ok","timestamp":1606444399878,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"HvlobeuOiTS9"},"outputs":[],"source":["def _action_sampler(k):\n","    return np.random.randint(0, k)\n","\n","# random action function\n","action_sampler = functools.partial(_action_sampler, k=K)"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":54395,"status":"ok","timestamp":1606444399879,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"IQCjTnKeiTS-"},"outputs":[],"source":["# Set the discount factor that discounts future rewards.\n","gamma = 0.99\n","\n","# Use epsilon-greedy for exploration\n","explorer = pfrl.explorers.ConstantEpsilonGreedy(\n","    epsilon=0.1, random_action_func=action_sampler)\n","\n","# DQN uses Experience Replay.\n","# Specify a replay buffer and its capacity.\n","replay_buffer = pfrl.replay_buffers.ReplayBuffer(capacity=10 ** 6, num_steps=50)"]},{"cell_type":"markdown","metadata":{"id":"I8OSpz80iTS-"},"source":["### Build DDQN\n","NOTE that since DeepRMSAv1 does not show sufficient information of hyper parameter, \n","we cannot reproduct it precisely. "]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":65056,"status":"ok","timestamp":1606444410544,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"1f1xA2nliTS-"},"outputs":[],"source":["# Now create an agent that will interact with the environment.\n","\n","DDQN = pfrl.agents.DQN(\n","    q_func,\n","    optimizer,\n","    replay_buffer,\n","    gamma,\n","    explorer,\n","    minibatch_size=50,\n","    update_interval=1,\n","    replay_start_size=500,\n","    target_update_interval=100,\n","    gpu=gpu,\n",")"]},{"cell_type":"markdown","metadata":{"id":"3iyucmBniTS-"},"source":["## Step 2: Develop your algorithm by using *KSPDRLAgent*\n","*RSA-RL* provides ***KSPDRLAgent*** that is based on *KSPAgent* class, which means that ***k-shortest path table***  can be used.   \n","You need to override two methods: \n","- `preprocess`: create *feature vector* from *observation*\n","- `map_drlout_to_action`: map outputs of DRL algorithms to *Action*"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":65058,"status":"ok","timestamp":1606444410549,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"dZMJKGKciTS-"},"outputs":[],"source":["import numpy as np\n","import networkx as nx\n","from rsarl.data import Action\n","from rsarl.agents import KSPDRLAgent\n","from rsarl.utils import cal_slot, sort_tuple\n","from rsarl.algorithms import SpectrumAssignment"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":65056,"status":"ok","timestamp":1606444410550,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"8xmSD5xhiTS-"},"outputs":[],"source":["def vectorize(n_nodes: int, node_id: int):\n","    mp = np.eye(n_nodes, dtype=np.float32)[node_id].reshape(-1, 1, 1)\n","    return mp\n","\n","class DRLAgent(KSPDRLAgent):\n","\n","    def preprocess(self, obs):\n","        \"\"\"\n","        \"\"\"\n","        net = obs.net\n","        source, destination, bandwidth, duration = obs.request\n","        # slot table\n","        whole_slot = np.array(list(nx.get_edge_attributes(net.G, name=\"slot\").values()))\n","        whole_slot = whole_slot.reshape(1, net.n_edges, net.n_slot).astype(np.float32)\n","        # source, destination, bandwidth map\n","        smap = np.ones_like(whole_slot) * vectorize(net.n_nodes, source)\n","        dmap = np.ones_like(whole_slot) * vectorize(net.n_nodes, destination)\n","        bmap = np.ones_like(whole_slot) * bandwidth\n","        # concate: (1, ICH, #edges, #slots)\n","        fvec = np.concatenate([whole_slot, smap, dmap, bmap], axis=0)\n","        return fvec.astype(np.float32, copy=False)\n","\n","    def map_drlout_to_action(self, obs, out):\n","        net = obs.net\n","        s, d, bandwidth, duration = obs.request\n","        paths = self.path_table[sort_tuple((s, d))]\n","        # map\n","        path = paths[out]\n","\n","        #required slots\n","        path_len = net.distance(path)\n","        n_req_slot = cal_slot(bandwidth, path_len)\n","        #FF\n","        path_slot = net.path_slot(path)\n","        slot_index = SpectrumAssignment.first_fit(path_slot, n_req_slot)\n","        if slot_index is None:\n","            return None\n","        else:\n","            return Action(path, slot_index, n_req_slot, duration)"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":65053,"status":"ok","timestamp":1606444410550,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"BHzndvTQiTS-"},"outputs":[],"source":["agent = DRLAgent(k=5, drl=DDQN)\n","# prepare path table\n","agent.prepare_ksp_table(net)"]},{"cell_type":"markdown","metadata":{"id":"Kho8Y5DJiTS-"},"source":["## Step 3: Training and Evaluate *DRL Agent*\n","Finally, let's training and evaluation! \n","Interaction between *Agent* with *Environment* automatically trains *Agent*.  \n","NOTE that before evaluation, you should change DRL model to ***evaluation mode*** by `eval_mode` method that *explore* does not run. "]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haDhbU40iTS-","outputId":"8aed44be-799c-48d4-97cf-d4c1592e3049"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0-th EVAL]\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function MultiprocessVectorEnv.__del__ at 0x000001E20EA8CA68>\n","Traceback (most recent call last):\n","  File \"c:\\Users\\khuatduc\\Desktop\\rsa-rl1\\tutorials\\rsarl\\envs\\multiprocess_vector_env.py\", line 61, in __del__\n","    if not self.closed:\n","AttributeError: 'MultiprocessVectorEnv' object has no attribute 'closed'\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22180/1514410202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtest_envs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22180/341560905.py\u001b[0m in \u001b[0;36m_evaluation\u001b[1;34m(envs, agent, n_requests)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_warming_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_requests\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_requests\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_requests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# calc performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mblocking_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_utils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\khuatduc\\Desktop\\rsa-rl1\\tutorials\\rsarl\\evaluator.py\u001b[0m in \u001b[0;36mbatch_evaluation\u001b[1;34m(vec_env, agent, n_requests)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mreq_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_requests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# Get action from observation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0macts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m# Do action and get next state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\khuatduc\\Desktop\\rsa-rl1\\tutorials\\rsarl\\agents\\agent.py\u001b[0m in \u001b[0;36mbatch_act\u001b[1;34m(self, batch_obs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbatch_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mdrl_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0macts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_drlout_to_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrl_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\khuatduc\\Desktop\\rsa-rl1\\tutorials\\rsarl\\agents\\agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbatch_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mdrl_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0macts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_drlout_to_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrl_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22180/1816727722.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mwhole_slot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhole_slot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_slot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# source, destination, bandwidth map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_slot\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mdmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_slot\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mbmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_slot\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Batch act\n","obses = envs.reset()\n","resets = [False for _ in range(len(obses))]\n","for train_cnt in range(200000):\n","    acts = agent.batch_act(obses)\n","    obses, rews, dones, infos = envs.step(acts)\n","    agent.batch_observe(obses, rews, dones, resets)\n","\n","    # Make mask(not_end). 0 if done/reset, 1 if pass\n","    not_end = np.logical_not(dones)\n","    obses = envs.reset(not_end)\n","    \n","    if train_cnt % 20000 == 0:\n","        print(f'[{train_cnt}-th EVAL]')\n","        test_envs.reset()\n","        with agent.drl.eval_mode():\n","            evaluation(agent=agent)"]},{"cell_type":"markdown","metadata":{"id":"XI9wtQr4iTS_"},"source":["## Conclusion"]},{"cell_type":"markdown","metadata":{"id":"tYEZwr7biTS_"},"source":["That's all! \n","This tutorial demonstrates how to develop DRL *Agent*. \n","Next tutorial demonstrate how to develop your own ***Environment***. "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":150595,"status":"ok","timestamp":1606444496103,"user":{"displayName":"下田将之","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBSV0yzOkNvYKgj70Klrh7A9Vq3AJsnlWlPn1e=s64","userId":"06013661169560345566"},"user_tz":-540},"id":"2gkjt9KIiTS_"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"03_DRL_Agent_en.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}
